{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing python packages for the analysis of data.\n",
    "\n",
    "### In this analysis, I will be using following packages:\n",
    "1. Python v3.0\n",
    "2. Numpy v1.12.1\n",
    "3. Pandas v0.20.1\n",
    "4. Plotly v2.0.8\n",
    "5. Cufflinks v0.8.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import plotly\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly import tools\n",
    "from helper.calc import *\n",
    "#import cufflinks as cf\n",
    "\n",
    "#plotly.offline.init_notebook_mode() # run at the start of every notebook\n",
    "plotly.tools.set_credentials_file(username='pankajs.phy', api_key='e0zYzuRpN5PC3GZV4zYC')\n",
    "#plotly.tools.set_config_file(world_readable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First I am importing the Excel data into the workspace in panda. The imported data will be stored in a pandas dataframe.\n",
    "### In the next step, all the column headings will be renamed. Basically, the whitespaces in the headings are replaced with an underscore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xl = pd.ExcelFile(\"./data/Consumer_1_profile_2010-2011.xlsx\",index=False)\n",
    "df = xl.parse(\"Sheet1\",index=False)\n",
    "df=df.rename(columns={\"Customer no.\" : \"Customer_No\", 'Consumption Category' : 'Consumption_Category','Period 1':'00:00','Period 2':'00:30','Period 3':'01:00','Period 4':'01:30','Period 5':'02:00','Period 6':'02:30','Period 7':'03:00','Period 8':'03:30','Period 9':'04:00','Period 10':'04:30','Period 11':'05:00','Period 12':'05:30','Period 13':'06:00','Period 14':'06:30','Period 15':'07:00','Period 16':'07:30','Period 17':'08:00','Period 18':'08:30','Period 19':'09:00','Period 20':'09:30','Period 21':'10:00','Period 22':'10:30','Period 23':'11:00','Period 24':'11:30','Period 25':'12:00','Period 26':'12:30','Period 27':'13:00','Period 28':'13:30','Period 29':'14:00','Period 30':'14:30','Period 31':'15:00','Period 32':'15:30','Period 33':'16:00','Period 34':'16:30','Period 35':'17:00','Period 36':'17:30','Period 37':'18:00','Period 38':'18:30','Period 39':'19:00','Period 40':'19:30','Period 41':'20:00','Period 42':'20:30','Period 43':'21:00','Period 44':'21:30','Period 45':'22:00','Period 46':'22:30','Period 47':'23:00','Period 48':'23:30'})\n",
    "df.head();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In the following code, the dataframe is splitted into three dataframes according to consumption category i.e., df_GG, df_CL and df_GC.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_GG=df[df.Consumption_Category=='GG']\n",
    "df_CL=df[df.Consumption_Category=='CL']\n",
    "df_GC=df[df.Consumption_Category=='GC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_GG.to_csv('./data/Consumer_1_2010-2011_GG.csv', encoding='utf-8',index=False)\n",
    "df_CL.to_csv('./data/Consumer_1_2010-2011_CL.csv', encoding='utf-8',index=False)\n",
    "df_GC.to_csv('./data/Consumer_1_2010-2011_GC.csv', encoding='utf-8',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_GG = pd.read_csv('./data/Consumer_1_2010-2011_GG.csv',\n",
    "                    parse_dates={'Date': [2,3,4]}, \n",
    "                    date_parser=lambda x: pd.datetime.strptime(x, '%d %m %Y'))\n",
    "\n",
    "\n",
    "df_CL = pd.read_csv('./data/Consumer_1_2010-2011_CL.csv',\n",
    "                    parse_dates={'Date': [2,3,4]}, \n",
    "                    date_parser=lambda x: pd.datetime.strptime(x, '%d %m %Y'))\n",
    "\n",
    "\n",
    "df_GC = pd.read_csv('./data/Consumer_1_2010-2011_GC.csv',\n",
    "                    parse_dates={'Date': [2,3,4]}, \n",
    "                    date_parser=lambda x: pd.datetime.strptime(x, '%d %m %Y'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from helper.interpolate import interpol\n",
    "\n",
    "#First Off-Peak Losses\n",
    "\n",
    "order = 1\n",
    "\n",
    "yi=[16.76,10.89,6.36,4.41,3.10,2.17,1.48,0.99,0.67,0.30]\n",
    "xi=[0.03,0.06,0.09,0.11,0.14,0.17,0.20,0.23,0.26,0.29]\n",
    "x=np.linspace(0,0.309,2000)\n",
    "\n",
    "df_loss_off_peak = pd.DataFrame({})\n",
    "df_loss_off_peak[\"Off_Peak_Consumption\"]=x\n",
    "df_loss_off_peak[\"Loss\"]=interpol(xi,yi,x,order)\n",
    "df_loss_off_peak[\"Loss\"][0]=0.0\n",
    "\n",
    "#Now Peak Consumption Losses with extrapolation\n",
    "\n",
    "yi = [1.79,2.92,3.55,4.24]\n",
    "xi = [0.46,0.49,0.51,0.54]\n",
    "x  = np.linspace(0.46,2.5,2000)\n",
    "\n",
    "df_loss_peak_geom = pd.DataFrame({})\n",
    "df_loss_peak_geom[\"Peak_Consumption\"]=x\n",
    "df_loss_peak_geom[\"Loss\"]=interpol(xi,yi,x,order)\n",
    "\n",
    "#Now Peak Consumption Losses without extrapolation\n",
    "yi = [1.79,2.92,3.55,4.24]\n",
    "xi = [0.46,0.49,0.51,0.54]\n",
    "x  = np.linspace(0.45,0.54,1000)\n",
    "y = interpol(xi,yi,x,order)\n",
    "\n",
    "x = np.append(x, np.array(np.linspace(0.540001,2.5,1000)))\n",
    "y = np.append(y, [4.24 for i in range(0,1000)])\n",
    "\n",
    "df_loss_peak = pd.DataFrame({})\n",
    "df_loss_peak[\"Peak_Consumption\"]=x\n",
    "df_loss_peak[\"Loss\"]=y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we create a new dataframe which contains the volume of discharge needed in each period for consumer1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = datetime.datetime(2010, 7, 1) #Start of the year\n",
    "end   = datetime.datetime(2011, 6, 30)#End of the year\n",
    "Dates = pd.date_range(start, end)#Series of the dates in the year 2010-2011\n",
    "\n",
    "df_vol_dschg = pd.DataFrame() #New dataframe for volme discharge\n",
    "df_vol_dschg['Date'] = Dates # Creating first column with dates\n",
    "\n",
    "df_consump = pd.DataFrame() #New dataframe for volme discharge\n",
    "df_consump['Date'] = Dates # Creating first column with dates\n",
    "\n",
    "for i in range(0,48): #Function to create new columns corresponding to volume discharge    \n",
    "    if(i%2 == 0):\n",
    "        if (i/2 <= 9):\n",
    "            key = '0'+str(int(i/2))+':00'\n",
    "        elif (i/2 >=10):\n",
    "            key = str(int(i/2))+':00'\n",
    "    elif(i%2 == 1):\n",
    "        if (i/2 < 10):\n",
    "            key = '0'+str(int(i/2))+':30'\n",
    "        elif (i/2 >=10):\n",
    "            key = str(int(i/2))+':30'\n",
    "            \n",
    "    df_vol_dschg[key] = dch_vol(df_GC,df_CL,df_GG,key); #Calling the function dch_vol to provide values to Period_1 to Period_48            \n",
    "    df_consump[key] = consump(df_GC,df_CL,key); #Calling the function consump to provide values to Period_1 to Period_48                \n",
    "\n",
    "# Converting Date column as datetime data type    \n",
    "df_vol_dschg['Date'] = pd.to_datetime(Dates) \n",
    "df_vol_dschg.index = df_vol_dschg['Date']\n",
    "#df_vol_dschg[\"Total\"] = df_vol_dschg.iloc[:,1:49].sum(axis=1)\n",
    "df_vol_dschg=df_vol_dschg.drop('Date',axis=1)\n",
    "\n",
    "# Writing the new dataframe into csv file\n",
    "df_vol_dschg.to_csv('./data/Consumer_1_2010-2011_discharge.csv', encoding='utf-8',index=False);\n",
    "\n",
    "# Converting Date column as datetime data type    \n",
    "df_consump['Date'] = pd.to_datetime(Dates) \n",
    "df_consump.index = df_consump['Date']\n",
    "#df_consump[\"Total\"] = df_consump.iloc[:,1:49].sum(axis=1)\n",
    "df_consump=df_consump.drop('Date',axis=1)\n",
    "# Writing the new dataframe into csv file\n",
    "df_consump.to_csv('./data/Consumer_1_2010-2011_consumption.csv', encoding='utf-8',index=False);\n",
    "df_consump.head();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Monthly_std_discharge = df_vol_dschg.resample('M').std()\n",
    "Monthly_mean_discharge = df_vol_dschg.resample('M').mean()\n",
    "Monthly_min_discharge  = df_vol_dschg.resample('M').min()\n",
    "Monthly_max_discharge  = df_vol_dschg.resample('M').max()\n",
    "\n",
    "Monthly_mean_discharge.describe();\n",
    "Monthly_std_discharge.iloc[:,1:10];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Trans_Monthly_mean = Monthly_mean_discharge.transpose();\n",
    "Trans_Monthly_min  = Monthly_min_discharge.transpose();\n",
    "Trans_Monthly_max  = Monthly_max_discharge.transpose();\n",
    "Trans_Monthly_std  = Monthly_std_discharge.transpose();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from helper.plot_plotly import plot_shaded\n",
    "ytitle = 'Mean half-hourly losses (cents)'\n",
    "plot_shaded(df_vol_dschg,'December',ytitle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from helper.plot_plotly import plot_multiplot\n",
    "Title='Mean variation of discharge volume across a financial year 2010-2011'\n",
    "#plot_multiplot(df_vol_dschg,Title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from helper.interpolate import interpol\n",
    "\n",
    "#First Off-Peak Losses\n",
    "\n",
    "order = 1\n",
    "\n",
    "yi=[16.76,10.89,6.36,4.41,3.10,2.17,1.48,0.99,0.67,0.30]\n",
    "xi=[0.03,0.06,0.09,0.11,0.14,0.17,0.20,0.23,0.26,0.29]\n",
    "x=np.linspace(0,0.309,2000)\n",
    "\n",
    "df_loss_off_peak = pd.DataFrame({})\n",
    "df_loss_off_peak[\"Off_Peak_Consumption\"]=x\n",
    "df_loss_off_peak[\"Loss\"]=interpol(xi,yi,x,order)\n",
    "df_loss_off_peak[\"Loss\"][0]=0.0\n",
    "\n",
    "#Now Peak Consumption Losses with extrapolation\n",
    "\n",
    "yi = [1.79,2.92,3.55,4.24]\n",
    "xi = [0.46,0.49,0.51,0.54]\n",
    "x  = np.linspace(0.46,2.5,2000)\n",
    "\n",
    "df_loss_peak_geom = pd.DataFrame({})\n",
    "df_loss_peak_geom[\"Peak_Consumption\"]=x\n",
    "df_loss_peak_geom[\"Loss\"]=interpol(xi,yi,x,order)\n",
    "\n",
    "#Now Peak Consumption Losses without extrapolation\n",
    "yi = [1.79,2.92,3.55,4.24]\n",
    "xi = [0.46,0.49,0.51,0.54]\n",
    "x  = np.linspace(0.45,0.54,1000)\n",
    "y = interpol(xi,yi,x,order)\n",
    "\n",
    "x = np.append(x, np.array(np.linspace(0.540001,2.5,1000)))\n",
    "y = np.append(y, [4.24 for i in range(0,1000)])\n",
    "\n",
    "df_loss_peak = pd.DataFrame({})\n",
    "df_loss_peak[\"Peak_Consumption\"]=x\n",
    "df_loss_peak[\"Loss\"]=y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Monthly_std_consump  = df_consump.resample('M').std()\n",
    "Monthly_mean_consump = df_consump.resample('M').mean()\n",
    "Monthly_min_consump  = df_consump.resample('M').min()\n",
    "Monthly_max_consump  = df_consump.resample('M').max()\n",
    "\n",
    "Monthly_mean_consump.describe();\n",
    "Monthly_std_consump.transpose().iloc[:,1:10];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'interpolate'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-a3cabbd3b0b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0minterpolate\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcost_consump\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mMonthly_mean_cost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMonthly_mean_consump\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mMonthly_mean_cost_geom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMonthly_mean_consump\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mMonthly_mean_cost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMonthly_mean_consump\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplymap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcost_consump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf_loss_peak\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf_loss_off_peak\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'interpolate'"
     ]
    }
   ],
   "source": [
    "from helper.interpolate import cost_consump\n",
    "Monthly_mean_cost = pd.DataFrame.copy(Monthly_mean_consump,deep=True)\n",
    "Monthly_mean_cost_geom = pd.DataFrame.copy(Monthly_mean_consump,deep=True)\n",
    "\n",
    "Monthly_mean_cost = Monthly_mean_consump.transpose().applymap(lambda x: cost_consump(x,df_loss_peak,df_loss_off_peak))\n",
    "Monthly_mean_cost_geom = Monthly_mean_consump.applymap(lambda x: cost_consump(x,df_loss_peak_geom,df_loss_off_peak))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Title='Mean Consumption losses across a financial year 2010-2011'\n",
    "figname = './plots/Mean_Cost.png'\n",
    "plot_multiplot(Monthly_mean_cost_geom,Title,figname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Title='Mean Consumption losses across a financial year 2010-2011'\n",
    "figname = './plots/Mean_Cost.png'\n",
    "plot_multiplot(Monthly_mean_cost_geom,Title,figname)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
